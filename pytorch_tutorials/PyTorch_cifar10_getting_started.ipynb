{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_cifar10_tutorial_ROB313_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4zsDWUk5cavn",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning for Image Classification\n",
        "\n",
        "Welcome to deep learning for image classification tutorial!\n",
        "**In this notebook, you will**:\n",
        "- Learn the basics of PyTorch, a powerful but easy to use package for scientific computing (and deep learning)\n",
        "- Learn how to build and train a convolutional neural network for image classification.\n",
        "\n",
        "If you have never used jupyter notebooks, nor Colab notebooks, [here](https://colab.research.google.com/notebooks/welcome.ipynb) is a short intro.\n",
        "\n",
        "\n",
        "## I. PyTorch Tutorial\n",
        "\n",
        "We will briefly go through the basics of the PyTorch package, playing with toy examples.\n",
        "\n",
        "If you know already how to use PyTorch, then you can directly go to the second part of this tutorial\n",
        "\n",
        "## II. Training a classifier\n",
        "\n",
        "In this part, we will train a Convolutional Neural Network to classify images of 10 different classes (dogs, cats, car, ...) and see how our model performs on the test set.  \n",
        "\n",
        "\n",
        "## III. Exploring CNN Architectures\n",
        "\n",
        "This is the part where you get your hands dirty ;). Your mission is to experiment different CNN architectures and set hyperparameters in order to obtain the best accuracy on the test set!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgRltjas9PpN",
        "colab_type": "text"
      },
      "source": [
        "The following command sets the backend of matplotlib to the 'inline' backend so that the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "GkjN23FKt2D-",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAz-fhRRdFaR",
        "colab_type": "text"
      },
      "source": [
        "### Plotting functions and useful imports\n",
        "\n",
        "You can skip this part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnee2WPudA9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python 2/3 compatibility\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Colors from Colorbrewer Paired_12\n",
        "colors = [[31, 120, 180], [51, 160, 44]]\n",
        "colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    \"\"\"\n",
        "    :param img: (PyTorch Tensor)\n",
        "    \"\"\"\n",
        "    # unnormalize\n",
        "    img = img / 2 + 0.5     \n",
        "    # Convert tensor to numpy array\n",
        "    npimg = img.numpy()\n",
        "    # Color channel first -> color channel last\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "\n",
        "def plot_losses(train_history, val_history):\n",
        "    x = np.arange(1, len(train_history) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, train_history, color=colors[0], label=\"Training loss\", linewidth=2)\n",
        "    plt.plot(x, val_history, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(\"Evolution of the training and validation loss\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    :param cm: (numpy matrix) confusion matrix\n",
        "    :param classes: [str]\n",
        "    :param normalize: (bool)\n",
        "    :param title: (str)\n",
        "    :param cmap: (matplotlib color map)\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        \n",
        "    plt.figure(figsize=(8, 8))   \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "aH_K9V7icav6",
        "colab_type": "text"
      },
      "source": [
        "# I. What is PyTorch ?\n",
        "\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "- A replacement for numpy to use the power of GPUs\n",
        "- A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "## PyTorch Basics\n",
        "\n",
        "In the next steps, we will briefly see how to use PyTorch and exploit its power:\n",
        "\n",
        "1. PyTorch Installation\n",
        "2. PyTorch Tensors\n",
        "3. Numpy Bridge\n",
        "4. Automatic differentiation\n",
        "5. PyTorch and GPU (CUDA support)\n",
        "\n",
        "\n",
        "### 1. Install PyTorch and Torchvision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0y5PLM6ciB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LcGVaagRcav8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# Import torch and create the alias \"th\"\n",
        "# instead of writing torch.name_of_a_method() , we only need to write th.name_of_a_method()\n",
        "# (similarly to numpy imported as np)\n",
        "import torch as th"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "g2-brDDHcawE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create tensor of ones (FloatTensor by default)\n",
        "ones = th.ones(3, 2)\n",
        "print(ones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6RvPibnScawC",
        "colab_type": "text"
      },
      "source": [
        "### 2. PyTorch Tensors\n",
        "\n",
        "A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type.\n",
        "\n",
        "Tensors are similar to numpy’s ndarrays, but they have a super-power: Tensors can also be used on a GPU to accelerate computing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "QcJgJQERcawQ",
        "colab_type": "text"
      },
      "source": [
        "#### Tensor Shape\n",
        "To know the shape of a given tensor, you can use the `.size()` method (the numpy equivalent is `.shape`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SI96-W9acawS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the shape of a tensor\n",
        "# it can be used as a tuple\n",
        "print(\"Tensor Shape: {}\".format(ones.size()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "pUPWrNarcawZ",
        "colab_type": "text"
      },
      "source": [
        "#### Reshape tensors\n",
        "\n",
        "To reshape tensors (e.g. flatten a 3D tensor to a 1D array), you can use the `.view()` method:\n",
        "\n",
        "- **x.view(new_shape)**: Returns a new tensor with the same data but different size. It is the equivalent of numpy function *reshape* (Gives a new shape to an array without changing its data.). You can read the full documentation [here.](http://pytorch.org/docs/master/tensors.html#torch.Tensor.view)\n",
        "\n",
        "[WARNING] when precising a new shape, you have to make sure that the number of elements is constant.\n",
        "For example, a 2D matrix of size 3x3 can only be viewed as a 1D array of size $3 \\cdot 3 = 9$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vX-oxI6Vcawb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a 3D tensor of size 3x2x2\n",
        "zeros_3d_tensor = th.zeros(3, 2, 2)\n",
        "print(\"Original size:\", zeros_3d_tensor.size())\n",
        "\n",
        "# Reshape it to a 1D array of size 3*2*2 = 12\n",
        "zeros_1d_array = zeros_3d_tensor.view(3 * 2 * 2)\n",
        "print(\"Reshaped tensor:\", zeros_1d_array.size())\n",
        "\n",
        "\n",
        "# Let's view our original tensor as a 2D matrix\n",
        "# If you want PyTorch to guess one remaining dimension,\n",
        "# you specify '-1' instead of the actual size\n",
        "zeros_2d_matrix = zeros_3d_tensor.view(-1, 2 * 2)\n",
        "\n",
        "print(\"Matrix shape:\", zeros_2d_matrix.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kTO_FFswcawj",
        "colab_type": "text"
      },
      "source": [
        "#### Basic Operations on tensors\n",
        "\n",
        "Tensor support all basic linear algebra operations. You can read the full documentation [here](http://pytorch.org/docs/master/tensors.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ay7LvYeVcawl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2 * ones + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OD7ZOT4jcaws",
        "colab_type": "text"
      },
      "source": [
        "PyTorch tensors also supports numpy indexing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "srzDzj_ocawu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\n Indexing Demo:\")\n",
        "print(ones[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "xrjqKguqcaw0",
        "colab_type": "text"
      },
      "source": [
        "### 3. Numpy Bridge\n",
        "WARNING: PyTorch Tensors are different from numpy arrays\n",
        "even if they have a lot in common\n",
        "\n",
        "Though, it is **easy with PyTorch to tranform Tensors to Numpy arrays and vice versa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gVAntrTVcaw3",
        "colab_type": "text"
      },
      "source": [
        "#### Numpy <-> PyTorch\n",
        "\n",
        "Creating PyTorch tensors from numpy array is done via the `torch.from_numpy()` function  \n",
        "(here `th.from_numpy()` because we renamed *torch* as *th*)\n",
        "\n",
        "To transform a PyTorch tensor to a numpy array, you can simply call `.numpy()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "t2ENcAKOcaw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.float32 -> th.FloatTensor\n",
        "ones_matrix = np.ones((2, 2), dtype=np.float32)\n",
        "\n",
        "# the matrix is passed by reference:\n",
        "# if we modify the original numpy array, the tensor is also edited\n",
        "ones_tensor = th.from_numpy(ones_matrix)\n",
        "# Convert back to a numpy matrix\n",
        "numpy_matrix = ones_tensor.numpy()\n",
        "\n",
        "print(\"PyTorch Tensor:\")\n",
        "print(ones_tensor)\n",
        "\n",
        "print(\"Numpy Matrix:\")\n",
        "print(numpy_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Y0Itjyg-caxD",
        "colab_type": "text"
      },
      "source": [
        "### 4. Automatic Differentiation\n",
        "\n",
        "Pytorch tensors allow to **automatically compute gradients**. That is particulary useful for backpropagation.\n",
        "\n",
        "Once you finish your computation you can call `.backward()` and have all the gradients computed automatically.\n",
        "\n",
        "You can access the gradient w.r.t. this variable using `.grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "WrPNcIpYcaxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to specify that we want to compute the gradient\n",
        "# as it requires extra memory and computation\n",
        "ones_tensor = th.ones(2,2, requires_grad=True)\n",
        "\n",
        "print(ones_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IEZDUibxcaxj",
        "colab_type": "text"
      },
      "source": [
        "To demonstrate the use of PyTorch Variable,\n",
        "let's define a simple linear transformation of a variable $x$ :\n",
        "\n",
        "$$y = a \\cdot x + b$$\n",
        "\n",
        "PyTorch will allows us to automatically compute $$\\frac{dy}{dx} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "A4j85JjZcaxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a tensor and tell PyTorch\n",
        "# that we want to compute the gradient\n",
        "x = th.ones(1, requires_grad=True)\n",
        "\n",
        "# Transformation constants\n",
        "a = 2\n",
        "b = 5\n",
        "\n",
        "# Define the tranformation and store the result\n",
        "# in a new variable\n",
        "y = a * x + b\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_mxnlvwxcaxq",
        "colab_type": "text"
      },
      "source": [
        "Let's backprop!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "X1i-pN-Fcaxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "skgIGZdmcaxw",
        "colab_type": "text"
      },
      "source": [
        "`x.grad` prints the gradient:\n",
        "\n",
        "$$\\frac{dy}{dx} = a$$\n",
        "\n",
        "because:\n",
        "\n",
        "$$y = a \\cdot x + b$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_TYbuwsXcaxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ggu-PBGvcax3",
        "colab_type": "text"
      },
      "source": [
        "You can now change the values of $a$ and $b$ see their effects on the gradient\n",
        "(HINT: `x.grad` only depends on the value of `a`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8iPn0C59cax5",
        "colab_type": "text"
      },
      "source": [
        "### 5. PyTorch and GPU (CUDA support)\n",
        "\n",
        "Google colab provides a CUDA enabled GPU, so we are going to use its power. \n",
        "You can move tensor to the GPU by simply using the `to()` method.\n",
        "Otherwise, PyTorch will use the CPU.\n",
        "\n",
        "Here, we will demonstrate the usefulness of the GPU on a simple matrix multiplication:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwF6ePTpeefQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if th.cuda.is_available():\n",
        "  # Create tensors\n",
        "  x = th.ones(1000, 1000)\n",
        "  y = 2 * x + 3\n",
        "  # Do the calculation on cpu (default)\n",
        "  start_time = time.time()\n",
        "  # Matrix multiplication (for benchmark purpose)\n",
        "  results = th.mm(x, y)\n",
        "  time_cpu = time.time() - start_time\n",
        "  \n",
        "  # Do the same calculation but on the gpu\n",
        "  # First move tensors to gpu\n",
        "  x = x.to(\"cuda\")\n",
        "  y = y.to(\"cuda\")\n",
        "  start_time = time.time()\n",
        "  # Matrix multiplication (for benchmark purpose)\n",
        "  results = th.mm(x, y)\n",
        "  time_gpu = time.time() - start_time\n",
        "  \n",
        "  print(\"Time on CPU: {:.5f}s \\t Time on GPU: {:.5f}s\".format(time_cpu, time_gpu))\n",
        "  print(\"Speed up: Computation was {:.0f}X faster on GPU!\".format(time_cpu / time_gpu))\n",
        "  \n",
        "else:\n",
        "  print(\"You need to enable GPU accelaration in colab (runtime->change runtime type)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-AOzDy9lFwi",
        "colab_type": "text"
      },
      "source": [
        "As expected, matrix multiplication is way faster on a GPU, so we'd better use it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "0kqEBjG6t2Eh"
      },
      "source": [
        "\n",
        "# II. Training a classifier\n",
        "\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "There are 10 classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "\n",
        "![CIFAR10](http://pytorch.org/tutorials/_images/cifar10.png)\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalize the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UWTdj2uYcax7",
        "colab_type": "text"
      },
      "source": [
        "### 1. Loading and normalizing CIFAR10 Dataset\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "KRrvrIi0t2Em",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iX2ltR_zcayA",
        "colab_type": "text"
      },
      "source": [
        "Seed the random generator to have reproducible results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "335xvR6acayB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if th.cuda.is_available():\n",
        "  # Make CuDNN Determinist\n",
        "  th.backends.cudnn.deterministic = True\n",
        "  th.cuda.manual_seed(seed)\n",
        "\n",
        "# Define default device, we should use the GPU (cuda) if available\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7EzIeyD4cayG",
        "colab_type": "text"
      },
      "source": [
        "### Define subset of the dataset (so it is faster to train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Nwu-wWh3cayI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "n_training_samples = 20000 # Max: 50 000 - n_val_samples\n",
        "n_val_samples = 5000\n",
        "n_test_samples = 5000\n",
        "\n",
        "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
        "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n",
        "# (In the last case, indexes do not need to account for training ones because the train=False parameter in datasets.CIFAR will select from the test set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "evFXNmbst2Ez"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "ZJ-hYN00t2E2",
        "colab": {}
      },
      "source": [
        "num_workers = 2\n",
        "test_batch_size = 4\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=test_batch_size, sampler=train_sampler,\n",
        "                                          num_workers=num_workers)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, sampler=test_sampler,\n",
        "                                         num_workers=num_workers)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "cGWVnBOft2FI"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "68OfC35ut2FM",
        "colab": {}
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('{:>10}'.format(classes[labels[j]]) for j in range(test_batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "8ULHEu5Zt2Fa"
      },
      "source": [
        "### 2. Define a Convolution Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6k6rJyTTcayi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful imports\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "0JcmlEe8t2Fe"
      },
      "source": [
        "####  Forward propagation\n",
        "\n",
        "In PyTorch, there are built-in functions that carry out the convolution steps for you.\n",
        "\n",
        "- **nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0):** Convolution layer. You can read the full documentation [here](http://pytorch.org/docs/master/nn.html#conv2d)\n",
        "\n",
        "- **nn.MaxPool2d(kernel_size, stride=None, padding=0):** Max pooling layer. You can read the full documentation [here](http://pytorch.org/docs/master/nn.html#maxpool2d)\n",
        "\n",
        "- **F.relu(Z1):** computes the elementwise ReLU of Z1 (which can be any shape). You can read the full documentation [here.](http://pytorch.org/docs/master/nn.html#torch.nn.ReLU)\n",
        "\n",
        "- **x.view(new_shape)**: Returns a new tensor with the same data but different size. It is the equivalent of numpy function *reshape* (Gives a new shape to an array without changing its data). You can read the full documentation [here.](http://pytorch.org/docs/master/tensors.html#torch.Tensor.view)\n",
        "\n",
        "- **nn.Linear(in_features, out_features):** Applies a linear transformation to the incoming data: $y = Ax + b$, it is also called a fully connected layer. You can read the full documentation [here.](http://pytorch.org/docs/master/nn.html#linear-layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rbykSRDTcaym",
        "colab_type": "text"
      },
      "source": [
        "#### Simple Convolutional Neural Network\n",
        "\n",
        "ConvNet with one convolution layer followed by a max pooling operation,\n",
        "one fully connected layer and an output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "X4pljAWycayn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvolutionalNetwork, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        # cf comments in forward() to have step by step comments\n",
        "        # on the shape (how we pass from a 3x32x32 input image to a 18x16x16 volume)\n",
        "        self.fc1 = nn.Linear(18 * 16 * 16, 64) \n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass,\n",
        "        x shape is (batch_size, 3, 32, 32)\n",
        "        (color channel first)\n",
        "        in the comments, we omit the batch_size in the shape\n",
        "        \"\"\"\n",
        "        # shape : 3x32x32 -> 18x32x32\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # 18x32x32 -> 18x16x16\n",
        "        x = self.pool(x)\n",
        "        # 18x16x16 -> 4608\n",
        "        x = x.view(-1, 18 * 16 * 16)\n",
        "        # 4608 -> 64\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 64 -> 10\n",
        "        # The softmax non-linearity is applied later (cf createLossAndOptimizer() fn)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4m-VHCtRcayr",
        "colab_type": "text"
      },
      "source": [
        "#### Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Rj-togN6cays",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear Classifier\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(32 * 32 * 3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten input 3x32x32 -> 3072\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "2SQi9Xf-t2Fu"
      },
      "source": [
        "### 3. Define a loss function and optimizer\n",
        "\n",
        "Let's use a Classification Cross-Entropy loss and ADAM (optionally, SGD with momentum). You can read more about  [optimization methods](https://pytorch.org/docs/stable/optim.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "DOUiPtZQt2Fx",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    # it combines softmax with negative log likelihood loss\n",
        "    criterion = nn.CrossEntropyLoss()  \n",
        "    #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    return criterion, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "saJW5bKRt2F9"
      },
      "source": [
        "### 4. Train the network\n",
        "\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, feed the inputs to the network, and optimize\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mNf1e8QZcay1",
        "colab_type": "text"
      },
      "source": [
        "#### Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "EqDD8_z8cay2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_loader(batch_size):\n",
        "    return torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler,\n",
        "                                              num_workers=num_workers)\n",
        "\n",
        "# Use larger batch size for validation to speed up computation\n",
        "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler,\n",
        "                                          num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yTDHHbLpcay5",
        "colab_type": "text"
      },
      "source": [
        "#### Training loop\n",
        "The training script: it takes ~10s per epoch with batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "dATbDR5pt2GE",
        "colab": {}
      },
      "source": [
        "def train(net, batch_size, n_epochs, learning_rate):\n",
        "    \"\"\"\n",
        "    Train a neural network and print statistics of the training\n",
        "    \n",
        "    :param net: (PyTorch Neural Network)\n",
        "    :param batch_size: (int)\n",
        "    :param n_epochs: (int)  Number of iterations on the training set\n",
        "    :param learning_rate: (float) learning rate used by the optimizer\n",
        "    \"\"\"\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"n_epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    n_minibatches = len(train_loader)\n",
        "\n",
        "    criterion, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    # Init variables used for plotting the loss\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "    best_error = np.inf\n",
        "    best_model_path = \"best_model.pth\"\n",
        "    \n",
        "    # Move model to gpu if possible\n",
        "    net = net.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        print_every = n_minibatches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Move tensors to correct device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # print every 10th of epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:    \n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                      epoch + 1, int(100 * (i + 1) / n_minibatches), running_loss / print_every,\n",
        "                      time.time() - start_time))\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "\n",
        "        train_history.append(total_train_loss / len(train_loader))\n",
        "\n",
        "        total_val_loss = 0\n",
        "        # Do a pass on the validation set\n",
        "        # We don't need to compute gradient,\n",
        "        # we save memory and computation using th.no_grad()\n",
        "        with th.no_grad():\n",
        "          for inputs, labels in val_loader:\n",
        "              # Move tensors to correct device\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              # Forward pass\n",
        "              predictions = net(inputs)\n",
        "              val_loss = criterion(predictions, labels)\n",
        "              total_val_loss += val_loss.item()\n",
        "            \n",
        "        val_history.append(total_val_loss / len(val_loader))\n",
        "        # Save model that performs best on validation set\n",
        "        if total_val_loss < best_error:\n",
        "            best_error = total_val_loss\n",
        "            th.save(net.state_dict(), best_model_path)\n",
        "\n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "\n",
        "    print(\"Training Finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
        "    \n",
        "    # Load best model\n",
        "    net.load_state_dict(th.load(best_model_path))\n",
        "    \n",
        "    return train_history, val_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cJX2anB5cay_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = SimpleConvolutionalNetwork()\n",
        "\n",
        "train_history, val_history = train(net, batch_size=32, n_epochs=10, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UkVKNPtccazC",
        "colab_type": "text"
      },
      "source": [
        "Now, let's look at the evolution of the losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4CUQt-HJcazF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_losses(train_history, val_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "O90WcUTwt2GU"
      },
      "source": [
        "### 5. Test the network on the test data\n",
        "\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "V4vljwBlt2GX",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  images, labels = next(iter(test_loader))\n",
        "except EOFError:\n",
        "  pass\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(\"Ground truth:\\n\")\n",
        "\n",
        "print(' '.join('{:>10}'.format(classes[labels[j]]) for j in range(test_batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "KpmaQT4Zt2Gn"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "utIfocFrt2Gs",
        "colab": {}
      },
      "source": [
        "outputs = net(images.to(device))\n",
        "print(outputs.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "6mU42O0Gt2G2"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "The higher the energy for a class, the more the network\n",
        "thinks that the image is from that particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "IWTWHHs9t2G5",
        "colab": {}
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print(\"Predicted:\\n\")\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print(' '.join('{:>10}'.format(classes[predicted[j]]) for j in range(test_batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "AUpCEAOTt2HK"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "LI6JtYwTt2HM",
        "colab": {}
      },
      "source": [
        "def dataset_accuracy(net, data_loader, name=\"\"):\n",
        "    net = net.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "    accuracy = 100 * float(correct) / total\n",
        "    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\n",
        "\n",
        "def train_set_accuracy(net):\n",
        "    dataset_accuracy(net, train_loader, \"train\")\n",
        "\n",
        "def val_set_accuracy(net):\n",
        "    dataset_accuracy(net, val_loader, \"validation\")  \n",
        "    \n",
        "def test_set_accuracy(net):\n",
        "    dataset_accuracy(net, test_loader, \"test\")\n",
        "\n",
        "def compute_accuracy(net):\n",
        "    train_set_accuracy(net)\n",
        "    val_set_accuracy(net)\n",
        "    test_set_accuracy(net)\n",
        "    \n",
        "print(\"Computing accuracy...\")\n",
        "compute_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "iGGyra-4t2HW"
      },
      "source": [
        "That initial 59.78 % on the test set of images looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "As a baseline, a linear model achieves around 30% accuracy.\n",
        "\n",
        "What are the classes that performed well, and the classes that did not perform well?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "rkim9_INt2HY",
        "colab": {}
      },
      "source": [
        "def accuracy_per_class(net):\n",
        "    net = net.to(device)\n",
        "    n_classes = 10\n",
        "    # (real, predicted)\n",
        "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        for i in range(test_batch_size):\n",
        "            confusion_matrix[labels[i], predicted[i]] += 1\n",
        "            label = labels[i]\n",
        "\n",
        "    print(\"{:<10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\n",
        "    for i in range(n_classes):\n",
        "        class_total = confusion_matrix[i, :].sum()\n",
        "        class_correct = confusion_matrix[i, i]\n",
        "        percentage_correct = 100.0 * float(class_correct) / class_total\n",
        "        \n",
        "        print('{:<10} {:^10.2f}'.format(classes[i], percentage_correct))\n",
        "    return confusion_matrix\n",
        "\n",
        "confusion_matrix = accuracy_per_class(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AZKLymOacazg",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ekJHz3vpcazg",
        "colab_type": "text"
      },
      "source": [
        "Let's look at what type of error our networks makes... \n",
        "It seems that our network is pretty good at classifying ships,\n",
        "but has some difficulties to differentiate cats and dogs.\n",
        "Also, it classifies a lot of trucks as cars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1aYMqD1Ocazi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(confusion_matrix, classes, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(confusion_matrix, classes,\n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "MVv-mV8Pt2Hs"
      },
      "source": [
        "# III. Exploring CNN Architectures\n",
        "\n",
        "Now, it is your turn to build a Convolutional Neural Network. The goal of this section is to explore different CNN architectures and set hyperparameters in order to obtain the best accuracy on the **test** set!\n",
        "\n",
        "The network that you have to tweak is called **MyConvolutionalNetwork**.\n",
        "\n",
        "You can start changing the batch_size, number of epochs and then try adding more convolutional layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "h1blK9eicazo",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch functions to build the network\n",
        "- **nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0):** Convolution layer. You can read the full documentation [here](http://pytorch.org/docs/master/nn.html#conv2d)\n",
        "\n",
        "- **nn.MaxPool2d(kernel_size, stride=None, padding=0):** Max pooling layer. You can read the full documentation [here](http://pytorch.org/docs/master/nn.html#maxpool2d)\n",
        "\n",
        "- **F.relu(Z1):** computes the element-wise ReLU of Z1 (which can be of any shape). You can read the full documentation [here.](http://pytorch.org/docs/master/nn.html#torch.nn.ReLU)\n",
        "\n",
        "- **x.view(new_shape)**: Returns a new tensor with the same data but different size. It is the equivalent of numpy function *reshape* (Gives a new shape to an array without changing its data.). You can read the full documentation [here.](http://pytorch.org/docs/master/tensors.html#torch.Tensor.view)\n",
        "\n",
        "- **nn.Linear(in_features, out_features):** Applies a linear transformation to the incoming data: $y = Ax + b$, it is also called a fully connected (fc) layer. You can read the full documentation [here.](http://pytorch.org/docs/master/nn.html#linear-layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "a8-lKBaacazp",
        "colab_type": "text"
      },
      "source": [
        "**Convolution Formulas**:\n",
        "\n",
        "The formulas relating the output shape $(C_2, H_2, W_2)$ of the convolution to the input shape $(C_1, H_1, W_1)$ are:\n",
        "\n",
        "\n",
        "$$ H_2 = \\lfloor \\frac{H_1 - kernel\\_size + 2 \\times padding}{stride} \\rfloor +1 $$\n",
        "\n",
        "$$ W_2 = \\lfloor \\frac{W_1 - kernel\\_size + 2 \\times padding}{stride} \\rfloor +1 $$\n",
        "\n",
        "$$ C_2 = \\text{number of filters used in the convolution}$$\n",
        "\n",
        "NOTE: $C_2 = C_1$ in the case of max pooling\n",
        "\n",
        "where:\n",
        "- $H_2$: height of the output volume  \n",
        "- $W_2$: width of the output volume  \n",
        "- $C_1$: in_channels, number of channels in the input volume\n",
        "- $C_2$: out_channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "acppf3nkcazr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    \"\"\"\n",
        "    Get the output size given all the parameters of the convolution\n",
        "    :param in_size: (int) input size\n",
        "    :param kernel_size: (int)\n",
        "    :param stride: (int)\n",
        "    :param paddind: (int)\n",
        "    :return: (int)\n",
        "    \"\"\"\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SEsbZoTOcazu",
        "colab_type": "text"
      },
      "source": [
        "#### Example of use of helper method get_output_size() \n",
        "\n",
        "Let's assume you have an *input volume of size 3x32x32* (where 3 is the number of channels)\n",
        "and you use a 2D convolution with the following parameters:\n",
        "\n",
        "```python\n",
        "conv1 = nn.Conv2d(3, 18, kernel_size=7, stride=2, padding=1)\n",
        "```\n",
        "then, the size of the output volume is 18x?x? (because we have 18 filters) where ? is given by the convolution formulas (see above).\n",
        "\n",
        "**get_output_size()** function allows to compute that size:\n",
        "\n",
        "```\n",
        "out_size = get_output_size(in_size=32, kernel_size=7, stride=2, padding=1)\n",
        "print(out_size) # prints 14\n",
        "```\n",
        "\n",
        "That is to say, *the output volume is 18x14x14*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "2JFQ1wgKcazv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_size = get_output_size(in_size=32, kernel_size=3, stride=1, padding=1)\n",
        "print(out_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wviV5iQIcazz",
        "colab_type": "text"
      },
      "source": [
        "Below is the neural network you have to edit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fnKUPUDTcaz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyConvolutionalNetwork, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        #### START CODE: ADD NEW LAYERS ####\n",
        "        # (do not forget to update `flattened_size`:\n",
        "        # the input size of the first fully connected layer self.fc1)\n",
        "        # self.conv2 = ...\n",
        "        \n",
        "        # Size of the output of the last convolution:\n",
        "        self.flattened_size = 18 * 16 * 16\n",
        "        ### END CODE ###\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass,\n",
        "        x shape is (batch_size, 3, 32, 32)\n",
        "        (color channel first)\n",
        "        in the comments, we omit the batch_size in the shape\n",
        "        \"\"\"\n",
        "        # shape : 3x32x32 -> 18x32x32\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # 18x32x32 -> 18x16x16\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        #### START CODE: USE YOUR NEW LAYERS HERE ####\n",
        "        # x = ...\n",
        "        \n",
        "        #### END CODE ####\n",
        "        \n",
        "        # Check the output size\n",
        "        output_size = np.prod(x.size()[1:])\n",
        "        assert output_size == self.flattened_size,\\\n",
        "                \"self.flattened_size is invalid {} != {}\".format(output_size, self.flattened_size)\n",
        "        \n",
        "        # 18x16x16 -> 4608\n",
        "        x = x.view(-1, self.flattened_size)\n",
        "        # 4608 -> 64\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 64 -> 10\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "scrolled": false,
        "id": "ruLWyTSocaz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = MyConvolutionalNetwork()\n",
        "train_history, val_history = train(net, batch_size=32, n_epochs=10, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "u7cgVbkDcaz9",
        "colab_type": "text"
      },
      "source": [
        "### Losses Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XtXu67qbcaz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_losses(train_history, val_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TuGKgAMWcaz_",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy of the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TWowqQhYca0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compute_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "st9f_4opca0F",
        "colab_type": "text"
      },
      "source": [
        "**Baseline: Simple Convolutional Neural Network (form part II)**\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "    <td>Accuracy on the test set:</td>\n",
        "    <td>59.98 %</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OKvmb4p-ca0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix = accuracy_per_class(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ih5Pj0WBca0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix, classes,\n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "7xzIkZqit2IA"
      },
      "source": [
        "### Going further\n",
        "\n",
        "- [Coursera Course on CNN](https://www.coursera.org/learn/convolutional-neural-networks)\n",
        "- [Stanford Course](http://cs231n.stanford.edu/syllabus.html)\n",
        "- [PyTorch Tutorial](http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
        "- [How backpropagation works](http://michaelnielsen.org/blog/how-the-backpropagation-algorithm-works/) (Michael Nielsen)\n",
        "\n",
        "If you feel like this was too easy peasy:\n",
        "\n",
        "-Investigate further [optimization methods](https://pytorch.org/docs/stable/optim.html) beyond SGD, and Adam and their parameters.\n",
        "\n",
        "-Look at ways to improve your network using regularization techniques\n",
        "\n",
        "-Look at ways to visualize network activations for model interpretability\n",
        "\n",
        "-Use transfer learning, in order to use torchvision with pretrained=True with some pretrained models\n",
        "\n",
        "\n",
        "Acknowledgements: \n",
        "This tutorial is based on the [original PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) and was adapted by [Antonin Raffin](http://araffin.github.io/) for the ROB313 course at ENSTA Paris. Thanks to Clement Pinard for feedback!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEFW6M6jZtWk",
        "colab_type": "text"
      },
      "source": [
        "### More documentation/ questions to explore about Google Colab: \n",
        "\n",
        "-How to connect your Google Drive with Google Colab?\n",
        "\n",
        "-How to import a new notebook and save it to your GDrive?\n",
        "\n",
        "-How to use files which are contained in your GDrive?\n",
        "\n",
        "Some tips [here](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Extras to read later\n",
        "### Visualizing Convolution parameters:\n",
        "[A guide to convolution arithmetic for deep learning](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) \n",
        "by Vincent Dumoulin, Francesco Visin \n",
        "\n",
        "\n",
        "### Documentation of autograd and Function: \n",
        "[Autograd](http://pytorch.org/docs/autograd)\n"
      ]
    }
  ]
}