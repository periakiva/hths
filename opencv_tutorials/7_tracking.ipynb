{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OpenCV-Python Tutorial] Object Tracking\n",
    "\n",
    "# TODO: Write description!!\n",
    "\n",
    "In this tutorial, we will understand the concepts of optical flow and its estimation using Lucas-Kanade method.\n",
    "and we will use functions like `cv2.calcOpticalFlowPyrLK()` to track feature points in a video.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import numpy as np\n",
    "import cv2 # OpenCV-Python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Open Video Controller\n",
    "# Only support file formats that HTML5 <video> playback supports(mp4, ogg, WebM).\n",
    "def open_video_controller(fpath, width = 480, height = 360):\n",
    "    display(HTML(data='''<video alt=\"test\" width=\"'''+ str(width) + '''\" height=\"''' + str(height) + '''\" controls>\n",
    "            <source src=\"''' + fpath + '''\" type=\"video/mp4\" />\n",
    "            </video>'''))\n",
    "\n",
    "def open_video_controller2(fpath, width = 480, height = 360):\n",
    "    video = io.open(fpath, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    display(HTML(data='''<video alt=\"test\" width=\"'''+ str(width) + '''\" height=\"''' + str(height) + '''\" controls>\n",
    "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "            </video>'''.format(encoded.decode('ascii'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open_video_controller(\"images/vtest.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open/Save a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open a video with cv2.VideoCapture\n",
    "vid = cv2.VideoCapture(\"images/vtest.mp4\")\n",
    "\n",
    "# Grab a frame\n",
    "ret, frame = vid.read()\n",
    "\n",
    "# Video\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the properties of video using get() method\n",
    "print(\"Frame width: %d\" % vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(\"Frame height: %d\" % vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(\"FPS: %d\" % vid.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grab the input device, in this case the webcam\n",
    "# You can also give path to the video file\n",
    "vid = cv2.VideoCapture(\"images/vtest.mp4\")\n",
    "\n",
    "# Put the code in try-except statements\n",
    "# Catch the keyboard exception and \n",
    "# release the camera device and \n",
    "# continue with the rest of code.\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Message to be displayed after releasing the device\n",
    "            print \"Released Video Resource\"\n",
    "            break\n",
    "        # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "        # to display the image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Turn off the axis\n",
    "        plt.axis('off')\n",
    "        # Title of the window\n",
    "        plt.title(\"Input Stream\")\n",
    "        # Display the frame\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        # Display the frame until new frame is available\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print \"Released Video Resource\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open a video and Save \n",
    "in_fpath = \"images/vtest.mp4\"\n",
    "v_in = cv2.VideoCapture(in_fpath)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out_fpath = \"images/vtest_flip.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "v_out = cv2.VideoWriter(out_fpath, fourcc, 10.0, (768, 576))\n",
    "\n",
    "while(v_in.isOpened()):\n",
    "    # Grab a frame\n",
    "    ret, frame = v_in.read()\n",
    "    if ret==True:\n",
    "        # flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # write the flipped frame\n",
    "        v_out.write(frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "v_in.release()\n",
    "v_out.release()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open_video_controller(\"images/vtest_flip.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up tracker.\n",
    "# Instead of MIL, you can also use\n",
    "# BOOSTING, KCF, TLD, MEDIANFLOW or GOTURN\n",
    "tracker = cv2.Tracker_create(\"MIL\")\n",
    "\n",
    "vid_fpath = \"images/vtest.mp4\"\n",
    "vid = cv2.VideoCapture(vid_fpath)\n",
    "\n",
    "# Read first frame.\n",
    "ok, frame = vid.read()\n",
    "if not ok:\n",
    "    print 'Cannot read video file'\n",
    "    sys.exit()\n",
    "\n",
    "# Define an initial bounding box\n",
    "bbox = (495, 155, 40, 80)\n",
    "\n",
    "# Uncomment the line below to select a different bounding box\n",
    "# bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ok = tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ok, frame = vid.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Update tracker\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    # Draw bounding box\n",
    "    if ok:\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (0,0,255))\n",
    "\n",
    "    # Display result\n",
    "#     cv2.imshow(\"Tracking\", frame)\n",
    "    # Display the frame\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    # Display the frame until new frame is available\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Write Practice!!!\n",
    "\n",
    "---\n",
    "\n",
    "## Practice: Edge Detection\n",
    "\n",
    "Find edges of the image below using **Canny edge detector**.\n",
    "- Convert the input image into grayscale.\n",
    "- You can choose appropriate values of the hysteresys thresholds.\n",
    "- Set `cmap='gray'` when display using `plt.imshow()`.\n",
    "\n",
    "Here's the input and a sample output\n",
    "![Desired output](images/xfiles_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's the input image\n",
    "image = cv2.imread('images/xfiles.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Write the code to find edges using cv2.Canny() method.\n",
    "# ============ YOUR CODE HERE ============\n",
    "output = np.zeros((360, 480), np.uint8)  # DUMMY\n",
    "# ========================================\n",
    "\n",
    "plt.figure(figsize=(8, 3));\n",
    "plt.subplot(1, 2, 1); plt.title('Input image'); plt.axis('off');\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));\n",
    "plt.subplot(1, 2, 2); plt.title('Output'); plt.axis('off');\n",
    "# ======= DISPLAY YOUR OUTPUT HERE =======\n",
    "plt.imshow(output, cmap='gray');  # DUMMY\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "Please see the following official tutorials and blog posts for more detailed explanation.\n",
    "\n",
    " - [Getting Started with Videos â€” OpenCV documentation](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html)\n",
    " - [OpenCV: Optical Flow](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_lucas_kanade.html)\n",
    " - (Blog) [Object Tracking using OpenCV (C++/Python)](https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
